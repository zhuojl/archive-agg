### 背景
在我们的项目中，数据进行了归档，并且可能异构数据源，在报表的``查询``或者常规业务查询时，往往需要合并多处的数据源，当然我们项目中有这样的框架，只是觉得有些不够好的地方，
虽然基于成本考虑，也不会替换现有框架，但还是想尝试一些想法，本来是提交了两版到公司gitlab仓库，但是也没人回应，所以还是提交到github，尝试维护。

最开始看公司框架除了代码混乱以外的主要问题，总感觉有点阅读障碍，以前的做法是提炼一个方法（query(objInstance, method)），并通过注解配置，
但是这样查阅到query的时候就断了，体验不好（但这情况随处可见，比如mybatis的mapper，这些通常是idea及插件支持）。所以打算自己写一套，能够阅读流畅，
并且解决常规场景的问题。

### 关于名字
一开始就叫sharding, 因为数据分片的原因；不满意后面因为数据组合，所以改叫compose；后来看了hadoop mapReduce，感觉有那么点意思（蹭蹭蹭。。。），
就改叫map-reduce了


### 需求


#### 参数解析，取分片键
1. 通过反射获取
2. 通过spEl解析
3. 通过实现特定的接口获取。

#### 请求路由
归档常按日期进行归档，比如一年前查某个mongo库，一月前查规格高一些的mongo库，一月内查mysql等。
根据查询的时间区间来确认需要查询哪类库。

#### 结果集归并
这个实现比较简单，尽量减少业务的配置

#### 分页
前期是很纠结这个，因为的确很难排序分页，内存和时间复杂度都支持不了，目前我们的框架和另外一个团队是按照先取热库再取冷库的方式来处理的。
这样总算有个解。

### 设计


### 疑惑