### 背景
在我们的项目中，数据进行了归档，并且可能异构数据源，在报表的``查询``或者常规业务查询时，往往需要合并多处的数据源，当然我们项目中有这样的框架，只是觉得有些不够好的地方，
虽然基于成本考虑，也不会替换现有框架，但还是想尝试一些想法，本来是提交了两版到公司gitlab仓库，但是也没人回应，所以还是提交到github，尝试维护。

最开始看公司框架除了代码混乱以外的主要问题，总感觉有点阅读障碍，以前的做法是提炼一个方法（query(objInstance, method)），并通过注解配置，
但是这样查阅到query的时候就断了，体验不好（但这情况随处可见，比如mybatis的mapper，这些通常是idea及插件支持）。所以打算自己写一套，能够阅读流畅，
并且解决常规场景的问题。

### 关于名字
一开始因为数据分片的原因, 叫sharding；不满意后面因为数据组合，所以改叫compose；后来看了hadoop mapReduce，感觉有那么点意思（蹭蹭蹭。。。），
改叫map-reduce了


### 需求

#### 参数解析，取分片键
1. 通过反射获取
2. 通过spEl解析
3. 通过实现特定的接口获取。

参数处理这里有个影响因素：数据在不同数据库之间是否有冗余（例如A区的范围是1-10, 由于数据安全考虑有冗余，实际为1-15， B区的范围是11-20）），
如果有冗余，需要考虑重设查询参数。比如查询8-12，那么查询A区时，应该通过8-10去查，查询B区用11-12去查，这样才不用考虑想通数据归并的问题。
类 com.zhuojl.map.reduce.ComposeParamHandler就是这个作用。在后续的设计中，不考虑数据冗余的情况，通过spEl解析分片键。

#### 请求路由
归档常按日期进行归档，比如一年前查某个mongo库，一月前查规格高一些的mongo库，一月内查mysql等。
根据查询的时间区间来确认需要查询哪类库。

#### 结果集归并
这个实现比较简单，尽量减少业务的配置

#### 分页
前期是很纠结这个，因为的确很难排序分页，内存和时间复杂度都支持不了，目前我们的框架和另外一个团队是按照先取热库再取冷库的方式来处理的。
这样总算有个解。

### 设计


### 疑惑


